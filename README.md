# Embedding_Fintuning_evaluation

ðŸ¤–sentence-transformers for embedding model evaluation and finetuning.

ðŸ¦™llama-index for training data augmentation.

# Requirements
```
Python 3.12.3
PyTorch: 2.4.0+cu121
pip install llama-index-llms-openai
pip install llama-index-embeddings-openai
pip install llama-index-finetuning
pip install sentence-transformers==3.0.1
pip install transformers==4.43.2
pip install accelerate==0.34.2
pip install datasets==2.21.0
```

# Evaluation Steps

step 1: Put embedding model to \model (run ```bash model_download.sh```), put evaluation datasets to \data.

step 2: run ```python embedding_evaluate.py --model bge-base-zh-v1.5 --dataset doc_qa_dataset.json```.


# Fine-Tuning

step 1 (optional): Data Augment if needed. Put corpus.txt to \docs. run ```python data_generate.py```.

step 2: Put training dataset and evaluation dataset to \data.

step 3: run ```python finetune.py --model bge-large-zh-v1.5 --train Dragon/train_dataset.json --val Dragon/val_dataset.json --hnm True```.

llama-index provides a data augment methodï¼š

Generate Corpus: https://docs.llamaindex.ai/en/stable/examples/finetuning/embeddings/finetune_embedding/#finetune-embeddings



# ä¼˜åŒ–ç‚¹
## ç”Ÿæˆè¯­æ–™

1ã€è‡ªå®šä¹‰MyLLMç±», æ›¿æ¢openai chatgpt3.5ï¼ˆä¸»è¦æ˜¯è€ƒè™‘åˆ°ðŸªœä»€ä¹ˆçš„å¾ˆéº»çƒ¦ï¼‰

LLMæ˜¯ç”¨çš„qwen2ï¼Œ éƒ¨ç½²æ–¹æ³•å‚è€ƒé¡¹ç›®(https://github.com/Yanchi98/Flask-vllm-qwen-)

é‡å†™æ–¹æ³•è§llm.pyï¼Œè¦å®žçŽ°completeæ–¹æ³•

2ã€ä¿®æ”¹promptï¼Œè®©queryä¸è¦è¶…è¿‡20char(è€ƒè™‘åˆ°ç”¨æˆ·è¾“å…¥é•¿queryçš„æ¦‚çŽ‡è¾ƒä½Ž)ï¼Œå¹¶ä¸”ä¸è¦å¸¦å¼•å¯¼è¯­

ä¿®æ”¹ä¹‹å‰ï¼š

promptä¸º

```
Context information is below.

---------------------
{context_str}
---------------------

Given the context information and not prior knowledge.
generate only questions based on the below query.

You are a Professor. Your task is to setup \
{num_questions_per_chunk} questions for an upcoming \
quiz/examination in Chinese. The questions should be diverse in nature \
across the document in Chinese. The questions should not contain options, not start with Q1/ Q2. \
Restrict the questions to the context information provided.
```

è¾“å‡ºç»“æžœä¸ºï¼š"1ã€è¯·ä»Žä¸‹é¢çš„æ–‡æ¡£ä¸­å›žç­”ï¼Œæ ¹æ®ç›¸å…³æœºæž„çš„ç»Ÿè®¡ï¼Œ2022å¹´å…¨çƒåŠå¯¼ä½“è®¾å¤‡é”€å”®é¢ä¸­ï¼Œå“ªä¸ªåœ°åŒºçš„é”€å”®é¢åŒæ¯”å¢žé•¿å¹…åº¦æœ€å¤§ï¼Ÿ"  -> é—®é¢˜å†—é•¿ã€å¸¦instruction

ä¿®æ”¹åŽï¼Œå¢žåŠ ä¸¤æ¡çº¦æŸï¼š

```
Context information is below.

---------------------
{context_str}
---------------------

Given the context information and not prior knowledge.
generate only questions based on the below query.

You are a Professor. Your task is to setup \
{num_questions_per_chunk} questions for an upcoming \
quiz/examination in Chinese. The questions should be diverse in nature \
across the document in Chinese. The questions should not contain options, not start with Q1/ Q2. \
Restrict the questions to the context information provided.
**The length of each question should not beyond 20 chars.
Directly give the question without start with any instruction.**
```

ä¿®æ”¹ä»¥åŽçš„æ•ˆæžœæ¯”è¾ƒå¥½ï¼š

![image](https://github.com/user-attachments/assets/642715e4-ea9a-46cc-91af-74ae7a2b9d3e)

3ã€ä¸­æ–‡å­˜åœ¨ç¼–ç é—®é¢˜ï¼Œå°†ç”Ÿæˆçš„datasetä¿å­˜ä¸ºjsonæ ¼å¼æ—¶ï¼Œè°ƒç”¨çš„æ˜¯lama_index/finetuning/embeddings/common.pyä¸­çš„save_jsonæ–¹æ³•ï¼Œéœ€è¦åŠ ä¸Šensure_ascii=False
```
 def save_json(self, path: str) -> None:
        """Save json."""
        with open(path, "w") as f:
            json.dump(self.dict(), f, indent=4, ensure_ascii=False)
```

